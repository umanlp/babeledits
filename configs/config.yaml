defaults:
  - model: llama-3-1
  - method: ft
  - decoding_strategy: greedy
  - _self_

metrics: 
  - token_em_lm_eval
  - rewrite_score
locality_metrics:
  - nkl
dataset: "datasets/v8/translated/test.json"
edit_lang: "en"
tgt_langs: ['ar', 'de', 'en', 'fr', 'hr', 'it', 'ja', 'ka', 'my', 'qu', 'zh']
multi_answer_eval: true
max_edits: null
device: 0
log_subdir: "new_debug"
prompt_type: "prompts_mt_marked"
subject_type: "subjects_mt_marked"
target_type: "targets_mt_marked"
eval_prompt_type: ["prompts_mt","prompts_mt_marked"]
subject_in_prompt: null
generality: true
locality: true
portability: true
eval_lm: true
data_lm : "data_ppl/ME-PPL_50_translated.json"
batch_size_lm: 24
lm_metric: "ppl"
pre_file: null
pre_edit: null
pre_eval_only: false
sequential: false
return_edited_weights: false
return_edited_weights_at_end: false
sample_idx: null